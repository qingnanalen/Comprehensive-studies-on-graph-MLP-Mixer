{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84eb06e-4ff1-41d3-9ed0-7ccc2253d3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "import metis\n",
    "from scipy import sparse as sp\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.datasets import MNISTSuperpixels\n",
    "from torch_sparse import SparseTensor\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f6b18c-387f-4323-b237-b33b3539dc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.get_device_name(0))\n",
    "def LapPE(edge_index, pos_enc_dim, num_nodes):\n",
    "    \"\"\"\n",
    "    Graph positional encoding using Laplacian eigenvectors.\n",
    "\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): Edge indices of the graph.\n",
    "        pos_enc_dim (int): Number of positional encoding dimensions.\n",
    "        num_nodes (int): Number of nodes in the graph.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Positional encodings of shape (num_nodes, pos_enc_dim).\n",
    "    \"\"\"\n",
    "    # Compute degree\n",
    "    degree = torch_geometric.utils.degree(edge_index[0], num_nodes)\n",
    "\n",
    "    # Create adjacency matrix\n",
    "    adj = torch.zeros((num_nodes, num_nodes), device=edge_index.device)\n",
    "    \n",
    "    adj[edge_index[0], edge_index[1]] = 1.0\n",
    "    # Normalize adjacency with degree\n",
    "    D_inv_sqrt = torch.diag(degree.clamp(min=1).pow(-0.5))\n",
    "    L = torch.eye(num_nodes, device=edge_index.device) - D_inv_sqrt @ adj @ D_inv_sqrt\n",
    "\n",
    "    # Compute eigenvalues and eigenvectors of Laplacian\n",
    "    eigvals, eigvecs = torch.linalg.eigh(L)\n",
    "\n",
    "    # Sort eigenvalues and eigenvectors in ascending order\n",
    "    idx = eigvals.argsort()\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "\n",
    "    # Extract first `pos_enc_dim` eigenvectors\n",
    "    pos_enc = eigvecs[:, 1:pos_enc_dim+1]\n",
    "\n",
    "    # Zero-pad if fewer eigenvectors are available\n",
    "    if pos_enc.size(1) < pos_enc_dim:\n",
    "        padding = pos_enc.new_zeros((num_nodes, pos_enc_dim - pos_enc.size(1)))\n",
    "        pos_enc = torch.cat([pos_enc, padding], dim=1)\n",
    "    #print(pos_enc)\n",
    "    #print(pos_enc.shape)\n",
    "    return pos_enc\n",
    "    \n",
    "def k_hop_subgraph(edge_index, num_nodes, num_hops, is_directed=False):\n",
    "    # Returns k-hop subgraphs for all nodes in the graph\n",
    "    if is_directed:\n",
    "        row, col = edge_index\n",
    "        birow, bicol = torch.cat([row, col]), torch.cat([col, row])\n",
    "        edge_index = torch.stack([birow, bicol])\n",
    "    else:\n",
    "        row, col = edge_index\n",
    "    \n",
    "    sparse_adj = SparseTensor(row=row, col=col, sparse_sizes=(num_nodes, num_nodes))\n",
    "    # Initialize masks and indicators for hop distances\n",
    "    hop_masks = [torch.eye(num_nodes, dtype=torch.bool, device=edge_index.device)]\n",
    "    hop_indicator = row.new_full((num_nodes, num_nodes), -1)\n",
    "    hop_indicator[hop_masks[0]] = 0\n",
    "    \n",
    "    for i in range(num_hops):\n",
    "        next_mask = sparse_adj.matmul(hop_masks[i].float()) > 0\n",
    "        hop_masks.append(next_mask)\n",
    "        hop_indicator[(hop_indicator == -1) & next_mask] = i + 1\n",
    "    \n",
    "    hop_indicator = hop_indicator.T  # N x N\n",
    "    node_mask = (hop_indicator >= 0)  # N x N dense mask matrix\n",
    "    return node_mask\n",
    "    \n",
    "# Function for METIS-based graph partitioning into subgraphs (patches)\n",
    "def metis_subgraph(g, n_patches, drop_rate=0.0, num_hops=1, is_directed=False):\n",
    "    # Check for directed or undirected configuration and partition the graph\n",
    "    if is_directed:\n",
    "        if g.num_nodes < n_patches:\n",
    "            membership = torch.arange(g.num_nodes)\n",
    "        else:\n",
    "            G = to_networkx(g, to_undirected=\"lower\")\n",
    "            cuts, membership = metis.part_graph(G, n_patches, recursive=True)\n",
    "    else:\n",
    "        if g.num_nodes < n_patches:\n",
    "            membership = torch.randperm(n_patches)\n",
    "        else:\n",
    "            # Data augmentation by edge dropping\n",
    "            adjlist = g.edge_index.t()\n",
    "            arr = torch.rand(len(adjlist))\n",
    "            selected = arr > drop_rate\n",
    "            G = nx.Graph()\n",
    "            G.add_nodes_from(np.arange(g.num_nodes))\n",
    "            G.add_edges_from(adjlist[selected].tolist())\n",
    "            # Partition graph using METIS\n",
    "            cuts, membership = metis.part_graph(G, n_patches, recursive=True)\n",
    "\n",
    "    assert len(membership) >= g.num_nodes\n",
    "    membership = torch.tensor(np.array(membership[:g.num_nodes]), device=g.edge_index.device)\n",
    "    max_patch_id = torch.max(membership) + 1\n",
    "    membership = membership + (n_patches - max_patch_id)\n",
    "\n",
    "    # Create a mask for each node in each patch\n",
    "    node_mask = torch.stack([membership == i for i in range(n_patches)])\n",
    "\n",
    "    if num_hops > 0:\n",
    "        subgraphs_batch, subgraphs_node_mapper = node_mask.nonzero(as_tuple=True)\n",
    "        k_hop_node_mask = k_hop_subgraph(g.edge_index, g.num_nodes, num_hops, is_directed)\n",
    "        node_mask.index_add_(0, subgraphs_batch, k_hop_node_mask[subgraphs_node_mapper])\n",
    "\n",
    "    # Mask for edges that connect nodes within each patch\n",
    "    edge_mask = node_mask[:, g.edge_index[0]] & node_mask[:, g.edge_index[1]]\n",
    "    return node_mask, edge_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9119c58-ccdc-44b9-a296-b2d25e5f04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GCN Model with Patch-Based Message Passing and Positional Encoding Injection\n",
    "class PatchGCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, pe_dim, patch_pe_dim, n_patches, num_hops=1, drop_rate=0.1):\n",
    "        super(PatchGCN, self).__init__()\n",
    "        # Adjusted GCN layer definitions to match the hidden_channels\n",
    "        self.conv1 = GCNConv(hidden_channels, hidden_channels*2)\n",
    "        self.conv2 = GCNConv(hidden_channels*2, hidden_channels*2)\n",
    "        self.conv3 = GCNConv(hidden_channels*2, hidden_channels)\n",
    "        self.conv4 = GCNConv(hidden_channels, out_channels)\n",
    "        self.T_node = nn.Linear(pe_dim, hidden_channels, bias=False)  # T^0\n",
    "        self.U_node = nn.Linear(in_channels, hidden_channels, bias=True)  # U^0 with bias\n",
    "        self.T_patch = nn.Linear(patch_pe_dim, hidden_channels, bias=False)  # T^hat\n",
    "        self.U_patch = nn.Linear(hidden_channels, hidden_channels, bias=True)  # U^hat with bias\n",
    "        self.patch_embedding_projection = nn.Linear(hidden_channels, hidden_channels, bias=True)\n",
    "        self.n_patches = n_patches\n",
    "        self.num_hops = num_hops\n",
    "        self.drop_rate = drop_rate\n",
    "        self.patch_pe_dim = patch_pe_dim\n",
    "        self.pe_dim = pe_dim\n",
    "        self.gelu = nn.GELU()\n",
    "    def process_graph(self, graph):\n",
    "        # METIS partitioning to extract patches (subgraphs)\n",
    "        node_mask, edge_mask = metis_subgraph(graph, n_patches=self.n_patches, drop_rate=self.drop_rate, num_hops=self.num_hops)\n",
    "        \n",
    "        # Compute node-level positional encoding\n",
    "        node_pos_enc = LapPE(graph.edge_index, pos_enc_dim=self.pe_dim, num_nodes=graph.num_nodes)\n",
    "        \"\"\"print(\"node PE: \")\n",
    "        print(node_pos_enc)\n",
    "        print(node_pos_enc.shape)\"\"\"\n",
    "        # Compute patch-level positional encoding\n",
    "        patch_adj = (node_mask.float() @ node_mask.float().T).long()\n",
    "        #print(\"patch-level ad matrix: \")\n",
    "        #print(patch_adj)\n",
    "        #print(torch.nonzero(patch_adj, as_tuple=False).T)\n",
    "        patch_pos_enc = LapPE(torch.nonzero(patch_adj, as_tuple=False).T, pos_enc_dim = self.patch_pe_dim , num_nodes = self.n_patches)\n",
    "        #print(\"patch PE: \")\n",
    "        #print(patch_pos_enc)\n",
    "        #print(patch_pos_enc.shape)\n",
    "        return node_pos_enc, patch_pos_enc, node_mask, edge_mask\n",
    "\n",
    "    def forward(self, batch):\n",
    "        all_patch_embeddings = []\n",
    "        batch_graphs = batch.to_data_list()\n",
    "\n",
    "        for graph in batch_graphs:\n",
    "            # Process each graph into patches\n",
    "            node_pos_enc, patch_pos_enc, node_mask, edge_mask = self.process_graph(graph)\n",
    "            # Inject node positional encodings\n",
    "            transformed_node_pos_enc = self.T_node(node_pos_enc)\n",
    "            transformed_node_features = self.U_node(graph.x)\n",
    "            node_features = transformed_node_pos_enc + transformed_node_features\n",
    "\n",
    "            # GCN propagation within each patch\n",
    "            patch_embeddings = []\n",
    "            for i in range(self.n_patches):\n",
    "                # Extract subgraph for each patch\n",
    "                node_indices = node_mask[i].nonzero(as_tuple=True)[0]\n",
    "                #print(node_indices)\n",
    "                edge_indices = edge_mask[i].nonzero(as_tuple=True)[0]\n",
    "                patch_x = node_features[node_indices]\n",
    "                patch_edge_index = graph.edge_index[:, edge_indices]\n",
    "\n",
    "                # Re-map edge indices to the local node indices in patch_x\n",
    "                node_index_map = {old_idx.item(): new_idx for new_idx, old_idx in enumerate(node_indices)}\n",
    "                remapped_patch_edge_index = []\n",
    "                for src, dst in patch_edge_index.t():\n",
    "                    if src.item() in node_index_map and dst.item() in node_index_map:\n",
    "                        remapped_patch_edge_index.append([node_index_map[src.item()], node_index_map[dst.item()]])\n",
    "                \n",
    "                if remapped_patch_edge_index:\n",
    "                    remapped_patch_edge_index = torch.tensor(remapped_patch_edge_index, dtype=torch.long).T.to(patch_edge_index.device)\n",
    "                else:\n",
    "                    remapped_patch_edge_index = torch.empty((2, 0), dtype=torch.long, device=patch_edge_index.device)\n",
    "\n",
    "                # Skip patches with no edges\n",
    "                if remapped_patch_edge_index.size(1) > 0:\n",
    "                    #print(\"GO\")\n",
    "                    x = self.gelu(self.conv1(patch_x, remapped_patch_edge_index))\n",
    "                    x = self.gelu(self.conv2(x, remapped_patch_edge_index))\n",
    "                    x = self.gelu(self.conv3(x, remapped_patch_edge_index))\n",
    "                    x = self.gelu(self.conv4(x, remapped_patch_edge_index)) + patch_x\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                # Pooling to get patch embedding\n",
    "                patch_embedding = torch.mean(x, dim=0)\n",
    "                patch_embedding = self.patch_embedding_projection(patch_embedding)\n",
    "                # Inject patch positional encodings\n",
    "                transformed_patch_pos_enc = self.T_patch(patch_pos_enc[i])\n",
    "                transformed_patch_embedding = self.U_patch(patch_embedding)\n",
    "                final_patch_embedding = transformed_patch_pos_enc + transformed_patch_embedding\n",
    "                patch_embeddings.append(final_patch_embedding)\n",
    "\n",
    "            # Stack patch embeddings for each graph\n",
    "            all_patch_embeddings.append(torch.stack(patch_embeddings, dim=0))\n",
    "\n",
    "        # Combine all patch embeddings for the batch\n",
    "        return torch.cat(all_patch_embeddings, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f9e5224-2cb0-46ab-b024-1e5c2e1b313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixerLayer(nn.Module):\n",
    "    def __init__(self, n_patches, hidden_channels, ds, dc):\n",
    "        \"\"\"\n",
    "        Mixer Layer consisting of Token Mixer and Channel Mixer.\n",
    "\n",
    "        Args:\n",
    "            n_patches (int): Number of patches (P).\n",
    "            hidden_channels (int): Hidden dimensionality (d).\n",
    "            ds (int): Dimensionality of the intermediate space in token mixing (d_s).\n",
    "            dc (int): Dimensionality of the intermediate space in channel mixing (d_c).\n",
    "        \"\"\"\n",
    "        super(MixerLayer, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(hidden_channels)\n",
    "\n",
    "        # Token Mixer\n",
    "        self.token_mixer_w1 = nn.Linear(n_patches, ds)\n",
    "        self.token_mixer_w2 = nn.Linear(ds, n_patches)\n",
    "\n",
    "        # Channel Mixer\n",
    "        self.channel_mixer_w3 = nn.Linear(hidden_channels, dc)\n",
    "        self.channel_mixer_w4 = nn.Linear(dc, hidden_channels)\n",
    "\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the Mixer Layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, n_patches, hidden_channels).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Processed tensor of the same shape as the input.\n",
    "        \"\"\"\n",
    "        # Token Mixing\n",
    "        token_mixing_input = self.layernorm(x)  # Apply layer norm\n",
    "        token_mixing_output = self.token_mixer_w1(token_mixing_input.permute(0, 2, 1))  # Permute for token mixing\n",
    "        token_mixing_output = self.gelu(token_mixing_output)  # Apply GELU activation\n",
    "        token_mixing_output = self.token_mixer_w2(token_mixing_output).permute(0, 2, 1)  # Permute back\n",
    "        x = x + token_mixing_output  # Add residual connection\n",
    "\n",
    "        # Channel Mixing\n",
    "        channel_mixing_input = self.layernorm(x)  # Apply layer norm\n",
    "        channel_mixing_output = self.channel_mixer_w3(channel_mixing_input)  # Apply first linear layer\n",
    "        channel_mixing_output = self.gelu(channel_mixing_output)  # Apply GELU activation\n",
    "        channel_mixing_output = self.channel_mixer_w4(channel_mixing_output)  # Apply second linear layer\n",
    "        x = x + channel_mixing_output  # Add residual connection\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3daf83a-1399-4c25-b397-ee650ba601e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMixer(nn.Module):\n",
    "    def __init__(self, patch_gcn, n_patches, hidden_channels, ds, dc, num_classes, num_mixer_layers):\n",
    "        \"\"\"\n",
    "        Graph Mixer model.\n",
    "\n",
    "        Args:\n",
    "            patch_gcn (PatchGCN): Instance of PatchGCN.\n",
    "            n_patches (int): Number of patches (P).\n",
    "            hidden_channels (int): Hidden dimensionality (d).\n",
    "            ds (int): Dimensionality of the intermediate space in token mixing (d_s).\n",
    "            dc (int): Dimensionality of the intermediate space in channel mixing (d_c).\n",
    "            num_classes (int): Number of output classes.\n",
    "            num_mixer_layers (int): Number of Mixer Layers.\n",
    "        \"\"\"\n",
    "        super(GraphMixer, self).__init__()\n",
    "        self.patch_gcn = patch_gcn\n",
    "        self.mixer_layers = nn.ModuleList([\n",
    "            MixerLayer(n_patches, hidden_channels, ds, dc) for _ in range(num_mixer_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "        Forward pass of the Graph Mixer.\n",
    "\n",
    "        Args:\n",
    "            batch (torch_geometric.data.Batch): Input batch of graphs.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Logits of shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        patch_embeddings = self.patch_gcn(batch)  # Shape: (batch_size * n_patches, hidden_channels)\n",
    "        #print(\"before batch\", patch_embeddings)\n",
    "        # Reshape patch embeddings for Mixer Layers\n",
    "        #print(\"inside\",batch.num_graphs)\n",
    "        batch_size = batch.num_graphs\n",
    "        patch_embeddings = patch_embeddings.view(batch_size, -1, patch_embeddings.size(-1))  # (batch_size, n_patches, hidden_channels)\n",
    "        #print(\"after batch\", patch_embeddings)\n",
    "        # Apply Mixer Layers\n",
    "        for mixer_layer in self.mixer_layers:\n",
    "            patch_embeddings = mixer_layer(patch_embeddings)\n",
    "\n",
    "        # Aggregate final patch embeddings for classification\n",
    "        graph_embeddings = patch_embeddings.mean(dim=1)  # Mean pooling over patches (batch_size, hidden_channels)\n",
    "\n",
    "        # Classify\n",
    "        logits = self.classifier(graph_embeddings)  # (batch_size, num_classes)\n",
    "        #print(\"output shape\", logits.shape)\n",
    "        return logits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f853f03a-ab63-46dc-a32f-d0dd43976877",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MNISTSuperpixels(root='data/MNIST')\n",
    "testset = MNISTSuperpixels(root='data/MNIST', transform=None, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c8ac73-ff09-42d8-ab9b-052f88c9dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "batch_size = 36\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-5\n",
    "\n",
    "# PatchGCN Parameters\n",
    "in_channels = trainset.num_node_features\n",
    "hidden_channels = 128\n",
    "out_channels = hidden_channels\n",
    "pe_dim = 16\n",
    "n_patches = 10\n",
    "patch_pe_dim = n_patches - 1\n",
    "num_hops = 1\n",
    "drop_rate = 0.1\n",
    "\n",
    "# Instantiate PatchGCN\n",
    "patch_gcn = PatchGCN(\n",
    "    in_channels=in_channels,\n",
    "    hidden_channels=hidden_channels,\n",
    "    out_channels=out_channels,\n",
    "    pe_dim=pe_dim,\n",
    "    patch_pe_dim=patch_pe_dim,\n",
    "    n_patches=n_patches,\n",
    "    num_hops=num_hops,\n",
    "    drop_rate=drop_rate,\n",
    ").to(device)\n",
    "\n",
    "# GraphMixer Parameters\n",
    "ds = 128  # Intermediate token mixing dimension\n",
    "dc = 256  # Intermediate channel mixing dimension\n",
    "num_classes = 10  # MNIST classification (digits 0-9)\n",
    "num_mixer_layers = 4  # Number of Mixer Layers\n",
    "\n",
    "# Instantiate GraphMixer\n",
    "model = GraphMixer(\n",
    "    patch_gcn=patch_gcn,\n",
    "    n_patches=n_patches,\n",
    "    hidden_channels=hidden_channels,\n",
    "    ds=ds,\n",
    "    dc=dc,\n",
    "    num_classes=num_classes,\n",
    "    num_mixer_layers=num_mixer_layers,\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b974a4a8-9662-41a8-98fa-079cc3108467",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = train_test_split(trainset, test_size=0.1)\n",
    "test_dataset = testset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56dd19ae-1b71-4344-87c1-3dbc3738afec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e99c6b66-631e-4486-82bc-cb3bad6919ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 76\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     74\u001b[0m start_epoch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 76\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train()\n\u001b[0;32m     77\u001b[0m val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m validate()\n\u001b[0;32m     78\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move data to GPU\u001b[39;00m\n\u001b[0;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 15\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(data)  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, data\u001b[38;5;241m.\u001b[39my)  \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 32\u001b[0m, in \u001b[0;36mGraphMixer.forward\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    Forward pass of the Graph Mixer.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m        torch.Tensor: Logits of shape (batch_size, num_classes).\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     patch_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_gcn(batch)  \u001b[38;5;66;03m# Shape: (batch_size * n_patches, hidden_channels)\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m#print(\"before batch\", patch_embeddings)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Reshape patch embeddings for Mixer Layers\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m#print(\"inside\",batch.num_graphs)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mnum_graphs\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 68\u001b[0m, in \u001b[0;36mPatchGCN.forward\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m src, dst \u001b[38;5;129;01min\u001b[39;00m patch_edge_index\u001b[38;5;241m.\u001b[39mt():\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;129;01min\u001b[39;00m node_index_map \u001b[38;5;129;01mand\u001b[39;00m dst\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;129;01min\u001b[39;00m node_index_map:\n\u001b[1;32m---> 68\u001b[0m         remapped_patch_edge_index\u001b[38;5;241m.\u001b[39mappend([node_index_map[src\u001b[38;5;241m.\u001b[39mitem()], node_index_map[dst\u001b[38;5;241m.\u001b[39mitem()]])\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remapped_patch_edge_index:\n\u001b[0;32m     71\u001b[0m     remapped_patch_edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(remapped_patch_edge_index, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mto(patch_edge_index\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training function with timing\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    batch_times = []  # Store batch processing times\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    for batch_idx, data in enumerate(progress_bar):\n",
    "        start_time = time.time()  # Start timer for the batch\n",
    "\n",
    "        data = data.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(data)  # Forward pass\n",
    "        loss = criterion(logits, data.y)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        end_time = time.time()  # End timer for the batch\n",
    "        batch_times.append(end_time - start_time)  # Record batch time\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"Loss\": loss.item()})  # Update tqdm bar\n",
    "\n",
    "    avg_batch_time = sum(batch_times) / len(batch_times)  # Average batch time\n",
    "    print(f\"Average Batch Time: {avg_batch_time:.4f} seconds, Total Batches: {len(train_loader)}\")\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Validation function with timing\n",
    "def validate():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    progress_bar = tqdm(val_loader, desc=\"Validating\", leave=False)\n",
    "    for batch_idx, data in enumerate(progress_bar):\n",
    "        start_time = time.time()\n",
    "\n",
    "        data = data.to(device)\n",
    "        logits = model(data)\n",
    "        loss = criterion(logits, data.y)\n",
    "        total_loss += loss.item()\n",
    "        pred = logits.argmax(dim=1)  # Predictions\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "\n",
    "        end_time = time.time()\n",
    "        progress_bar.set_postfix({\"Batch Time (s)\": f\"{end_time - start_time:.4f}\"})\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    accuracy = correct / len(val_dataset)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Testing function with timing\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    progress_bar = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "    for batch_idx, data in enumerate(progress_bar):\n",
    "        start_time = time.time()\n",
    "\n",
    "        data = data.to(device)\n",
    "        logits = model(data)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "\n",
    "        end_time = time.time()\n",
    "        progress_bar.set_postfix({\"Batch Time (s)\": f\"{end_time - start_time:.4f}\"})\n",
    "\n",
    "    return correct / len(test_dataset)\n",
    "\n",
    "# Training loop with timing and tqdm\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "    start_epoch_time = time.time()\n",
    "\n",
    "    train_loss = train()\n",
    "    val_loss, val_accuracy = validate()\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    test_accuracy = test()\n",
    "    scheduler.step(val_loss)  # Update learning rate based on validation loss\n",
    "\n",
    "    end_epoch_time = time.time()\n",
    "    epoch_time = end_epoch_time - start_epoch_time  # Time taken for the epoch\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch}, \"\n",
    "        f\"Train Loss: {train_loss:.4f}, \"\n",
    "        f\"Val Loss: {val_loss:.4f}, \"\n",
    "        f\"Val Accuracy: {val_accuracy:.4f}, \"\n",
    "        f\"Test Accuracy: {test_accuracy:.4f}, \"\n",
    "        f\"Epoch Time: {epoch_time:.2f} seconds\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e8b8b5-481c-4ce1-93be-0775aa64f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss', marker='o')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss', marker='o')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
